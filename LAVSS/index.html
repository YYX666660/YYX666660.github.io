<html lang="en" class="LAVSS_tsinghua_vip">

<head>
    <!-- Required meta tags -->
    <title>Location-Guided Audio-Visual Spatial Audio Separation</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="keywords"
        content="video, sound, audio, deep learning, computer vision, machine learning">
    <meta name="description" content="n">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css">

    <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-81724582-4"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments) };
        gtag('js', new Date());
        gtag('config', 'UA-81724582-4');
    </script>

    <style>
        body {
            font-size: 16px
        }
        .navbar-fixed-top {
            min-height: 60px;
        }

        .navbar-nav>li>a {
            padding-top: 0px;
            padding-bottom: 0px;
            line-height: 60px;
            font-size: 22px;
            color:gray;
        }
        
        .navbar-nav>li>a:active {
            color:white;
        }
        
        .navbar-nav>li>a:hover {
            color:white;
            -webkit-tap-highlight-color: rgba(0,0,0,0);
            -webkit-tap-highlight-color:transparent;
            outline:none;
            background:none;
            text-decoration: none;
        }
        

    </style>
    <!-- Custom styles for this template -->
    <link href="jumbotron.css" rel="stylesheet">
</head>



<body data-gr-c-s-loaded="true">
    <nav class="navbar-fixed-top" style="background-color: rgb(44, 42, 42)">
        <a class="navbar-brand" href="#" style="font-size: 25px; color:white">LAVSS</a>

        <div class="collapse navbar-collapse" id="navbarsExampleDefault">
            <ul class="nav navbar-nav mr-auto" >
                <li><a href="#Video" style="font-size: 20px">Video</a></li>
                <li><a href="#Code" style="font-size: 20px">Code</a></li>
                <li><a href="#More" style="font-size: 20px">More</a></li>
            </ul>
        </div>
    </nav>


    <main role="main">
        <div class="container" style="padding-top: 80px; font-size: 20px">
            <div align="center">
                <h1 class="text-center" aligh="center">
                    Location-Guided Audio-Visual Spatial Audio Separation
                </h1><br>

                <b>Yuxin Ye</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=vsE4nKcAAAAJ"><b>Wenming Yang</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="http://www.yapengtian.com/"><b>Yapeng Tian</b></a> &nbsp;&nbsp;&nbsp; &nbsp;
	<br><br><br><br>
 	<center>
    	<img src="teaser_figure.png" width="800" height="450" alt="feature" />
    	</center>

                <br>
            </div>
        </div>

        <br>

        <div class="container">
            <h3 id="RFSleep" style="padding-top: 80px; margin-top: -80px;">Abstract:</h3>
            <hr>
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
		<p style="text-align:justify">
                    Existing machine learning research has achieved promising results in monaural audio-visual separation (MAVS). However, most MAVS methods purely consider what
the sound source is, not where it is located. This can be a problem in VR/AR scenarios, where listeners need to be able to distinguish between similar audio sources located in different directions. To address this limitation, we have
generalized MAVS to spatial audio separation and proposed LAVSS: a location-guided audio-visual spatial audio separator. LAVSS is inspired by the correlation between spatial audio and visual location. We introduce the phase
difference carried by binaural audio as spatial cues, and we utilize positional representations of sounding objects as additional modality guidance. We also leverage multi-level cross-modal attention to perform visual-positional
collaboration with audio features. In addition, we adopt a pre-trained monaural separator to transfer knowledge from rich mono sounds to boost spatial audio separation. This exploits the correlation between monaural and binaural
channels. Experiments on the FAIR-Play dataset demonstrate the superiority of the proposed LAVSS over existing benchmarks of audio-visual separation.

                </div>
                <div style='margin-top: 280px'>
                 <div class="col-md-10 col-md-offset-1">
                </div>
            </div>
        </div>
        <br><br>


        <div class="container">
            <h3 id="Video" style="padding-top: 80px; margin-top: -80px;">Video:</h3>
            <hr>
            <div class="col-md-1"></div>
            <div class="col-md-10">
                <div class="embed-responsive embed-responsive-16by9">
                    <iframe src="https://player.bilibili.com/player.html?aid=615188298&bvid=BV14h4y1g7p8&cid=1176486836&page=1&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
                </div>
            </div>
        </div><br><br>


        <div class="container">
            <h3 id="Code" style="padding-top: 80px; margin-top: -80px;">Code:</h3>
            <hr>
            <div class="row">
                <div class="col-md-9">
                        Code is avaliable.
                        </b><br></a>

                    Yuxin Ye <br>    
                    <a href="https://github.com/YYX666660/LAVSS">[Code]<br></a>
                </div>
            </div>
        </div><br><br>


        </div><br><br>



        <div class="container">
            <h3 id="More" style="padding-top: 80px; margin-top: -80px;">Related Publications</h3>
            <hr>

            <div class="row">
                <div class="col-md-9">
                    <b><a target="_blank" href="https://arxiv.org/pdf/2104.02026.pdf">
                            <font color="black">Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation </font>
                        </a></b><br>
                    <a href="http://www.yapengtian.com/">Yapeng Tian</a>,
                    <a href="https://dtaoo.github.io/">Di Hu</a>,
                    <a href="https://www.cs.rochester.edu/~cxu22/">Chenliang Xu</a>
                    
                    <br>
                    <i>CVPR 2021 </i><br>
                </div>
            </div>

          <div class="row">
                <div class="col-md-9">
                    <b><a target="_blank" href="https://av4d.org/papers/iccv23/p8.pdf">
                            <font color="black">Position-Aware Audio-Visual Separation for Spatial Audio </font>
                        </a></b><br>
                    Yuxin Ye</a>,
                    <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=vsE4nKcAAAAJ">Wenming Yang</a>,
                    <a href="http://www.yapengtian.com/">Yapeng Tian</a>
                    
                    <br>
                    <i>ICCV 2023 Workshop </i><br>
                </div>
            </div>	
       
        </div><br><br>
            
    </main>

</body>

</html>
